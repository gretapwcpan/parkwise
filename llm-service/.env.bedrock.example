# AWS Bedrock Configuration Example
# Copy this file to .env and fill in your AWS credentials

# LLM API Type - set to "bedrock" to use AWS Bedrock
LLM_API_TYPE=bedrock

# AWS Configuration
AWS_REGION=us-east-1
# AWS_REGION=us-west-2  # Alternative region

# AWS Credentials (Optional - can also use IAM role or AWS CLI config)
# AWS_ACCESS_KEY_ID=your_access_key_here
# AWS_SECRET_ACCESS_KEY=your_secret_key_here
# AWS_SESSION_TOKEN=your_session_token_here  # Only for temporary credentials

# Bedrock Model Configuration
# For Claude models on Bedrock:
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
# BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0
# BEDROCK_MODEL_ID=anthropic.claude-instant-v1

# For Llama models on Bedrock:
# BEDROCK_MODEL_ID=meta.llama2-13b-chat-v1
# BEDROCK_MODEL_ID=meta.llama2-70b-chat-v1
# BEDROCK_MODEL_ID=meta.llama3-8b-instruct-v1:0
# BEDROCK_MODEL_ID=meta.llama3-70b-instruct-v1:0

# For Mistral models on Bedrock:
# BEDROCK_MODEL_ID=mistral.mistral-7b-instruct-v0:2
# BEDROCK_MODEL_ID=mistral.mixtral-8x7b-instruct-v0:1

# For Amazon Titan models:
# BEDROCK_MODEL_ID=amazon.titan-text-express-v1
# BEDROCK_MODEL_ID=amazon.titan-text-lite-v1

# For Cohere models:
# BEDROCK_MODEL_ID=cohere.command-text-v14
# BEDROCK_MODEL_ID=cohere.command-light-text-v14

# For AI21 models:
# BEDROCK_MODEL_ID=ai21.j2-mid-v1
# BEDROCK_MODEL_ID=ai21.j2-ultra-v1

# Service Configuration
PORT=8001
HOST=0.0.0.0
DEBUG=false
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001
LOG_LEVEL=INFO

# LangGraph Configuration
TEMPERATURE=0  # For consistent parsing
MAX_RETRIES=3
